# RunPod Endpoint – Notes (draft)

## Account checklist

- [x ] GitHub linked (verified Mark0025)
- [x ] Payment method / credits ($25 showing)
- [ ] SSH key added for pod access

## Desired default pod

| Parameter     | Value                                                |
| ------------- | ---------------------------------------------------- |
| GPU           | RTX 4090 (24 GB)                                     |
| Template      | "Ollama" community template (ID: **ollama/ollama** ) |
| Disk          | 80 GB (increase later if model >13B)                 |
| Ports         | 11434 (Ollama) exposed                               |
| Pricing       | On-demand $0.69/hr (switch to Flex later)            |
| Auto-shutdown | 10 min idle via cron or API                          |

> NOTE: Flex workers need HTTP+SSE keep-alive; stick to on-demand for Phase 1.

## API endpoints

- **Pods API** `https://api.runpod.ai/v2/pod`
  - `POST /launch` → returns `podId`
  - `POST /status` → check `RUNNING`
  - `POST /stop` → halt pod

Store `RUNPOD_API_KEY` in 1Password & `.env` (git-ignored).

## CLI quick-start (using runpod)

Install & login:

```bash
pipx install runpod  # isolates CLI
runpod configure --api-key $RUNPOD_API_KEY
```

Launch the default pod:

```bash
runpod pod launch --template-id ollama/ollama \
    --gpu-count 1 --disk-size 80 --name devloop-ollama \
    --ports "11434:http"
```

Check status & get IP:

```bash
runpod pod status --name devloop-ollama
```

Stop the pod:

```bash
runpod pod stop --name devloop-ollama
```

## Architecture Overview

Local Dev Machine → RunPod API
- `runpod` CLI (installed via `pipx`) launches & controls pods.
- `.env` stores `RUNPOD_CLI_API_KEY` only; project Python deps unaffected.

Controller API (FastAPI, hosted on VPS or home server)
- Receives `/infer` calls from agents.
- Calls RunPod REST (or CLI) to start pod if needed, forwards prompt.

RunPod Pod (Ollama template)
- Model server on port 11434.
- Auto-shutdown handled by controller idle timer.

---

## Initial test commands (after pod is running)

```bash
curl http://<pod-ip>:11434/api/tags                # list models
curl http://<pod-ip>:11434/api/generate \
     -d '{"model":"mistral:7b-instruct-q5_K_M","prompt":"2+2="}'
```

## TODO

- Decide between Ollama vs FastAPI agent container (compare startup times).
- Script idle timer (Python or bash) → add to Phase 1 tasks.
